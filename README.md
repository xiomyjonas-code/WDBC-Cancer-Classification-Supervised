# Supervised Machine Learning: Breast Cancer Diagnosis (WDBC) üß¨ 
**Author:** xiomyjonas-code   
**Area:** Bioinform√°tica (Algoritmos e Inteligencia Artificial)

Este proyecto presenta un an√°lisis comparativo utilizando algoritmos de **Aprendizaje Autom√°tico Supervisado** para la clasificaci√≥n de tumores de mama (Malignos vs. Benignos) utilizando el conjunto de datos *Wisconsin Diagnostic Breast Cancer (WDBC)*.

El estudio contrasta el rendimiento de modelos modernos (SVM, Random Forest, k-NN) frente a los est√°ndares de referencia establecidos en la literatura m√©dica cl√°sica (Wolberg et al., 1995).

## Objetivos üéØ 
1. **Optimizaci√≥n de Modelos:** Implementar y ajustar hiperpar√°metros para Support Vector Machines (SVM), Random Forest (RF) y k-Nearest Neighbors (k-NN).
2. **Validaci√≥n Cruzada:** Garantizar la robustez de los resultados mediante *10-fold Cross-Validation*.
3. **Benchmarking:** Comparar la precisi√≥n diagn√≥stica del "Gold Standard" (3 variables nucleares) frente a modelos entrenados con selecci√≥n de caracter√≠sticas optimizada (21 variables).

## Stack Tecnol√≥gico üõ†Ô∏è 
* **Lenguaje:** R
* **Machine Learning:** `caret` (Training & Tuning), `kernlab` (SVM), `randomForest`, `class`.
* **Visualizaci√≥n & An√°lisis:** `pROC` (Curvas ROC), `ggplot2`, `corrplot`.

## Metodolog√≠a y Afinaci√≥n de Modelos üî¨ 

Se realiz√≥ una b√∫squeda de hiperpar√°metros (*Tuning*) para maximizar el √Årea Bajo la Curva (AUC).

### 1. Random Forest
Se evalu√≥ el n√∫mero de predictores seleccionados aleatoriamente en cada divisi√≥n (*mtry*).
* **Resultado √ìptimo:** El modelo alcanz√≥ su m√°ximo rendimiento (ROC $\approx$ 0.9895) con **15 predictores** (`mtry = 15`). Aumentar a 20 predictores result√≥ en una ligera ca√≠da del rendimiento por sobreajuste.

### 2. k-Nearest Neighbors (k-NN)
Se analiz√≥ el impacto del tama√±o del vecindario (*k*) en la capacidad de generalizaci√≥n.
* **Resultado √ìptimo:** Se identific√≥ un pico de rendimiento (ROC $\approx$ 0.985) con **$k = 21$ vecinos**. Esto sugiere que una frontera de decisi√≥n m√°s suave favorece la clasificaci√≥n en este dataset.

### 3. Support Vector Machine (SVM)
Se implement√≥ un SVM con **Kernel Lineal**. Debido a la clara separabilidad lineal de los datos en el hiperespacio, el modelo convergi√≥ √≥ptimamente con el par√°metro de coste por defecto, logrando un desempe√±o superior sin necesidad de kernels radiales complejos.

## Resultados Finales üìä

El modelo **SVM Lineal** demostr√≥ ser el clasificador m√°s robusto, superando ligeramente a Random Forest y k-NN en las m√©tricas finales sobre el conjunto de prueba.

| Modelo | AUC (ROC) | Sensibilidad (Maligno)* | Especificidad (Benigno)* |
| :--- | :---: | :---: | :---: |
| **SVM Lineal** | **0.998** | **92.8%** | **98.6%** |
| Random Forest | 0.997 | 92.8% | 98.5% |
| k-NN ($k=21$) | 0.985 | 92.8% | 97.5% |

*> Nota: M√©tricas ajustadas considerando "Maligno" como la clase positiva de inter√©s cl√≠nico.*

## üí° Conclusi√≥n
El an√°lisis valida que, aunque los modelos no lineales como Random Forest y k-NN ofrecen un rendimiento excelente ($>97\%$ AUC), la naturaleza de los datos biol√≥gicos del WDBC permite una clasificaci√≥n casi perfecta utilizando un separador lineal (SVM). Esto respalda el principio de parsimonia en bioinform√°tica cl√≠nica: modelos m√°s simples y explicables pueden ser igual o m√°s efectivos que arquitecturas complejas.

## üìÇ Estructura del Repositorio
* `supervisado_analysis.R`: C√≥digo fuente completo en R.
* `data/`: carpeta con los archivos `data.csv`(Dataset WDBC) y `variables.csv` (informaci√≥n del dataset)
* `plots/`: Carpeta con gr√°ficos de afinaci√≥n y curvas ROC.
---

*Proyecto desarrollado para el M√°ster en Bioinform√°tica.*
